{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaea759b-39e3-4637-a268-2a94e35f4871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba8e70b3-90f5-4a5a-8a1e-075949c821f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- country: string (nullable = true)\n |-- state: string (nullable = true)\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df=spark.createDataFrame(data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09d39166-3826-49c1-95fe-955be3af85b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.orc(\"/FileStore/tables/Orcdata1.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69eb0dc8-d481-4e6e-b050-cc52834a15e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: DataFrame[firstname: string, lastname: string, country: string, state: string]"
     ]
    }
   ],
   "source": [
    "spark.read.orc(\"/FileStore/tables/Orcdata.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "255f86ed-689a-40e3-874f-12a33cfcebe8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Taking the files from web\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "from pyspark import SparkFiles\n",
    "spark.sparkContext.addFile(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb09140-a1e6-46a4-8fb0-e8d547251386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#reading the file to create the dataframe\n",
    "df = spark.read.csv(\"file://\"+SparkFiles.get(\"iris.data\"), inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c11bd2-2b0b-43fc-b4a0-b6b4be80b803",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- _c0: double (nullable = true)\n |-- _c1: double (nullable = true)\n |-- _c2: double (nullable = true)\n |-- _c3: double (nullable = true)\n |-- _c4: string (nullable = true)\n\n+---+---+---+---+-----------+\n|_c0|_c1|_c2|_c3|        _c4|\n+---+---+---+---+-----------+\n|5.1|3.5|1.4|0.2|Iris-setosa|\n|4.9|3.0|1.4|0.2|Iris-setosa|\n|4.7|3.2|1.3|0.2|Iris-setosa|\n|4.6|3.1|1.5|0.2|Iris-setosa|\n|5.0|3.6|1.4|0.2|Iris-setosa|\n|5.4|3.9|1.7|0.4|Iris-setosa|\n|4.6|3.4|1.4|0.3|Iris-setosa|\n|5.0|3.4|1.5|0.2|Iris-setosa|\n|4.4|2.9|1.4|0.2|Iris-setosa|\n|4.9|3.1|1.5|0.1|Iris-setosa|\n|5.4|3.7|1.5|0.2|Iris-setosa|\n|4.8|3.4|1.6|0.2|Iris-setosa|\n|4.8|3.0|1.4|0.1|Iris-setosa|\n|4.3|3.0|1.1|0.1|Iris-setosa|\n|5.8|4.0|1.2|0.2|Iris-setosa|\n|5.7|4.4|1.5|0.4|Iris-setosa|\n|5.4|3.9|1.3|0.4|Iris-setosa|\n|5.1|3.5|1.4|0.3|Iris-setosa|\n|5.7|3.8|1.7|0.3|Iris-setosa|\n|5.1|3.8|1.5|0.3|Iris-setosa|\n+---+---+---+---+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#priting the column and showing the information\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a3ffa0-20a9-4582-921d-b5da17a1fe34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+-------------------+\n|_c0|_c1|_c2|_c3|        _c4|              class|\n+---+---+---+---+-----------+-------------------+\n|5.1|3.5|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.9|3.0|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.7|3.2|1.3|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.6|3.1|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.0|3.6|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.9|1.7|0.4|Iris-setosa|Iris-Dataset-setosa|\n|4.6|3.4|1.4|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.0|3.4|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.4|2.9|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.9|3.1|1.5|0.1|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.7|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.8|3.4|1.6|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.8|3.0|1.4|0.1|Iris-setosa|Iris-Dataset-setosa|\n|4.3|3.0|1.1|0.1|Iris-setosa|Iris-Dataset-setosa|\n|5.8|4.0|1.2|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.7|4.4|1.5|0.4|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.9|1.3|0.4|Iris-setosa|Iris-Dataset-setosa|\n|5.1|3.5|1.4|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.7|3.8|1.7|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.1|3.8|1.5|0.3|Iris-setosa|Iris-Dataset-setosa|\n+---+---+---+---+-----------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1=df.withColumn(\"class\", regexp_replace(\"_c4\", \"Iris\", \"Iris-Dataset\"))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7579c2f4-2655-4075-a5eb-e01e2fa5a236",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[58]: ['Iris-Dataset-versicolor', 'Iris-Dataset-virginica', 'Iris-Dataset-setosa']"
     ]
    }
   ],
   "source": [
    "df1.select('class').distinct().rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caa417ea-f5f3-446b-8fcd-7858fa032a37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n|summary|               _c0|                _c1|               _c2|               _c3|           _c4|\n+-------+------------------+-------------------+------------------+------------------+--------------+\n|  count|               150|                150|               150|               150|           150|\n|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|          null|\n| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|          null|\n|    min|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n|    max|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n+-------+------------------+-------------------+------------------+------------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Computing basic statistics for numeric and string columns\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e313677d-a416-4a38-8e43-eff862c021c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "address = [(1,\"14851 Jeffrey Rd\",\"DE\"),\n",
    "    (2,\"43421 Margarita St\",\"NY\"),\n",
    "    (3,\"13111 Siemon Ave\",\"CA\")]\n",
    "                                                                                        Columns-id, address,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "659e43f3-3f29-478f-b21d-a16d25e08f0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+\n| id|           address|state|\n+---+------------------+-----+\n|  1|  14851 Jeffrey Rd|   DE|\n|  2|43421 Margarita St|   NY|\n|  3|  13111 Siemon Ave|   CA|\n+---+------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"Replace\").getOrCreate()\n",
    "address = [(1,\"14851 Jeffrey Rd\",\"DE\"),\n",
    "    (2,\"43421 Margarita St\",\"NY\"),\n",
    "    (3,\"13111 Siemon Ave\",\"CA\")]\n",
    "df =spark.createDataFrame(address,[\"id\",\"address\",\"state\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd912c2-58fd-4e28-9516-85a06aec2402",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+------------------+\n| id|           address|state|          address1|\n+---+------------------+-----+------------------+\n|  1|  14851 Jeffrey Rd|   DE|14851 Jeffrey Road|\n|  2|43421 Margarita St|   NY|43421 Margarita St|\n|  3|  13111 Siemon Ave|   CA|  13111 Siemon Ave|\n+---+------------------+-----+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# replace \"rd\" with \"road\" in the address column\n",
    "df1=df.withColumn(\"address1\", regexp_replace(\"address\", \"Rd\", \"Road\"))\n",
    "\n",
    "# show the updated DataFrame\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52bce4c1-d786-45ff-b56e-7e5c997f96d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "df_lastest = spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a65e354-0898-4054-b63f-1cc80d46cd52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"first_name\", StringType(), True),\n",
    "        StructField(\"middle_name\", StringType(), True),\n",
    "        StructField(\"last_name\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"languages\", ArrayType(StringType(), True), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "\n",
    "detail_df=spark.createDataFrame(data,schema)\n",
    "detail_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a48beafb-11c7-4a92-9a7d-04a36b2a5536",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#detail df with OH state\n",
    "detail=detail_df.filter(detail_df.state ==\"OH\")\n",
    "detail.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80cdb8a4-a5f2-48a4-82a0-35804e443641",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#detail df with not OH state\n",
    "detail=detail_df.filter(detail_df.state !=\"OH\")\n",
    "detail.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38c9462-3179-46d4-9a31-ebdd433a61c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#name middle name is not empty\n",
    "detail=detail_df.filter(detail_df.name.middle_name !=\"\")\n",
    "detail.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f327c59d-7158-41dc-b970-1618e67a4cf3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n| {Julia, , Williams}|      [CSharp, VB]|   DE|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   CA|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"DE\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"CA\",\"M\")\n",
    " ]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"first_name\", StringType(), True),\n",
    "        StructField(\"middle_name\", StringType(), True),\n",
    "        StructField(\"last_name\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"languages\", ArrayType(StringType(), True), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "\n",
    "latest_df=spark.createDataFrame(data,schema)\n",
    "latest_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c9c46b-6b4a-4d7a-bd27-8ec38796b10e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n| {Julia, , Williams}|      [CSharp, VB]|   DE|     F|\n|{Mike, Mary, Will...|      [Python, VB]|   CA|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#whether oh or ca or de\n",
    "detail=latest_df.filter((latest_df.state == \"OH\") | (latest_df.state == \"CA\") | (latest_df.state == \"DE\"))\n",
    "detail.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08456489-d8c7-4fa3-95c4-a12126d54e33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----+------+\n|name|languages|state|gender|\n+----+---------+-----+------+\n+----+---------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#states which starts from H\n",
    "detail = latest_df.filter(latest_df.state.startswith(\"H\"))\n",
    "detail.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f77c594-dc8a-4622-a656-6b57eec72fa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+------+\n|                name|   languages|state|gender|\n+--------------------+------------+-----+------+\n|{Mike, Mary, Will...|[Python, VB]|   CA|     M|\n+--------------------+------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# states which end A\n",
    "detail = latest_df.filter(latest_df.state.endswith(\"A\"))\n",
    "detail.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a50b2f5-3a0a-4b25-9385-f8e5d0fcec63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+------+\n|                name|   languages|state|gender|\n+--------------------+------------+-----+------+\n|{Mike, Mary, Will...|[Python, VB]|   CA|     M|\n+--------------------+------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#states which has C contains\n",
    "detail = latest_df.filter(latest_df.state.like(\"%C%\"))\n",
    "detail.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebf4bcea-b274-4447-aeef-ea8a2e04f8f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Spark_Session",
   "notebookOrigID": 2521248266669651,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
